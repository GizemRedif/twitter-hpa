services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      # Zookeeper'ın 2181 portunda TCP bağlantısı kabul edip etmediğini kontrol eder. (nc ile)
      # Servisin ayağa kalkıp portu dinlemeye başladığını doğrulamak için kullanılır.
      # Kafka gibi bağımlı servislerin daha güvenli başlatılmasını sağlar. 
      # (Kafka’nın Zookeeper 2181 portunu dinlemeye başlamadan önce başlatılmasını kısmen engeller.)
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "2181" ]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Kafka topic'lerini otomatik oluşturur
  # tweets.raw: 3 partition, 7 gün retention, cleanup.policy=delete
  # tweets.alert: 1 partition, 1 gün retention
  # Kafka'ya bağlanır, tweets.raw'dan AVRO formatında tweet'leri okur ve işler.
  # Negatif sentiment'e sahip tweet'leri "tweets.alert" topic'ine yazar.
  # Confluent Schema Registry üzerinden şema çözümlemesi yapar.
  # 1 Partition nedeni: Alert'ler sırayla okunmalıdır. Verim önemsiz, latency önemlidir.
  init-kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: init-kafka
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      echo 'Waiting for Kafka to be ready...'
      cub kafka-ready -b kafka:29092 1 30

      echo 'Creating tweets.raw topic...'
      kafka-topics --create --if-not-exists \
        --bootstrap-server kafka:29092 \
        --topic tweets.raw \
        --partitions 3 \
        --replication-factor 1 \
        --config retention.ms=604800000 \
        --config cleanup.policy=delete

      echo 'Creating tweets.alert topic...'
      kafka-topics --create --if-not-exists \
        --bootstrap-server kafka:29092 \
        --topic tweets.alert \
        --partitions 1 \
        --replication-factor 1 \
        --config retention.ms=86400000

      echo 'Topics created!'
      kafka-topics --list --bootstrap-server kafka:29092
      "
    restart: "no"

  # Confluent Schema Registry: AVRO şema yönetimi için kullanılır.
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    depends_on:
      - kafka
    ports:
      - "8083:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081/subjects" ]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka-producer:
    build: ./kafka_producer
    container_name: kafka-producer
    depends_on:
      schema-registry:
        condition: service_healthy
    # Python loglarının (print vb.) terminalde anlık olarak görünmesini sağlar.
    environment:
      PYTHONUNBUFFERED: "1"
    restart: "no"

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"

  mongo:
    image: mongo:6
    container_name: mongo
    ports:
      - "27017:27017"
    volumes:
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro

  mongo-alert-consumer:
    build: ./mongo_alert_consumer
    container_name: mongo-alert-consumer
    depends_on:
      - kafka
      - mongo
    environment:
      PYTHONUNBUFFERED: "1"
    restart: on-failure

  mongo-raw-consumer:
    build: ./mongo_raw_consumer
    container_name: mongo-raw-consumer
    depends_on:
      schema-registry:
        condition: service_healthy
      mongo:
        condition: service_started
    environment:
      PYTHONUNBUFFERED: "1"
    restart: on-failure

  airflow:
    image: apache/airflow:2.7.1
    container_name: airflow
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    ports:
      - "8081:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
    command: >
      bash -c " airflow db init && airflow users create
        --username admin
        --password admin
        --firstname admin
        --lastname admin
        --role Admin
        --email admin@example.com &&
      airflow webserver & airflow scheduler "

  #Flink master node, işleri yönetir (Web UI 8082)
  flink-jobmanager:
    image: flink:1.18
    container_name: flink-jobmanager
    ports:
      - "8082:8081"
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
    command: jobmanager
    depends_on:
      - kafka

  #Flink worker node, işleri yapar
  flink-taskmanager:
    image: flink:1.18
    container_name: flink-taskmanager
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
    command: taskmanager
    depends_on:
      - flink-jobmanager
